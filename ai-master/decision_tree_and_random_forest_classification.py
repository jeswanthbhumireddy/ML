# -*- coding: utf-8 -*-
"""Decision_Tree_and_Random_Forest_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DP2rFffyOiXK-QeQCnLm-wYEXFpcATAp

## NLP Text Classification

### Import the Libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import re
import nltk

"""### Download NLTK"""

nltk.download('all')

"""### Read the restaurant review file"""

# quoting = 3 will ignore double quotes
dataset = pd.read_csv('https://raw.githubusercontent.com/futurexskill/ai/master/Restaurant_Reviews.tsv', delimiter = '\t', quoting = 3)

dataset.head()

# Sample sentence
dataset['Review'][0]

# Sample sentence
dataset['Review'][6]

"""### Import Stop Words"""

from nltk.corpus import stopwords

"""### Import Stemmer Class"""

from nltk.stem.porter import PorterStemmer

"""Instantiate the Stemmer"""

ps = PorterStemmer()

"""### Create a Corpus of clean text

Loop through all 1000 reviews
Apply Regular expression , Stemming and Stopwords to get a corpus of clean words
"""

corpus = []
for i in range(0, 1000):
    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])
    review = review.lower()
    review = review.split()
    ps = PorterStemmer()
    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]
    review = ' '.join(review)
    corpus.append(review)

"""Now you have the corpus of clean text"""

## Sample sentence after cleansing, stemming and applying stop words
corpus[0]

## Sample sentence after cleansing, stemming and applying stop words
corpus[6]

"""### Create the Tf-Idf model for all reviews"""

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features = 1500, min_df = 3, max_df = 0.6)

"""Store the featurized TF-IDF array in X"""

X = vectorizer.fit_transform(corpus).toarray()

# TF-IDF vector for sample sentences
#X[0]

"""Store the Last column "Liked" in y"""

y = dataset.iloc[:, 1].values

"""### Train Test split"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

"""### Build a KNN Classifier"""

# Training the KNN model
from sklearn.neighbors import KNeighborsClassifier
# minkowski is for ecledian distance
classifierKNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifierKNN.fit(X_train, y_train)

"""### Build a Naive Bayes Classifier"""

#from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
#classifier = GaussianNB()
classifierNB = MultinomialNB()
classifierNB.fit(X_train, y_train)

"""### Build a Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
classifierDT = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifierDT.fit(X_train, y_train)

"""### Build a Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
#n_estimators is the number of trees you want in the forest
classifierRF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifierRF.fit(X_train, y_train)

"""### Evaluate all models"""

y_pred_knn = classifierKNN.predict(X_test)

y_pred_NB = classifierNB.predict(X_test)

y_pred_DT = classifierDT.predict(X_test)

y_pred_RF = classifierRF.predict(X_test)

from sklearn.metrics import classification_report, accuracy_score,confusion_matrix

cmknn = confusion_matrix(y_test, y_pred_knn)
cmknn

cmNB = confusion_matrix(y_test, y_pred_NB)
cmNB

cmDT = confusion_matrix(y_test, y_pred_DT)
cmDT

cmRF = confusion_matrix(y_test, y_pred_RF)
cmRF

print("KNN accuracy \n", accuracy_score(y_test,y_pred_knn))

print("Naive Bayes accuracy \n", accuracy_score(y_test,y_pred_NB))

print("Decision Tree accuracy \n", accuracy_score(y_test,y_pred_DT))

print("Random Forest accuracy \n", accuracy_score(y_test,y_pred_RF))

"""## Naive Bayes gives higher accuracy so we will use that to predict output for new data"""

sample = ["Good batting by England"]

# create the TF-IDF model of the sample sentence
sample = vectorizer.transform(sample).toarray()

#predict the sentiment
sentiment = classifierNB.predict(sample)
if (sentiment==1):
    print("Good Review")
else:
    print("Bad Review")

sample2 = ["bad performance by India in the match"]
sample2 = vectorizer.transform(sample2).toarray()
sentiment2 = classifierNB.predict(sample2)
if (sentiment2==1):
    print("Good Review")
else:
    print("Bad Review")

